# AI Bill of Materials Agent System

An intelligent agent system that automatically generates, compares, and analyzes AI Bill of Materials (AIBOMs) for Hugging Face models using the OWASP AIBOM Generator and AWS AgentCore runtime.

## Overview

This project creates an autonomous agent that:
- Fetches model information from Hugging Face
- Generates AIBOMs using the OWASP AIBOM Generator
- Performs comparative analysis between different models
- Identifies security risks and compliance gaps
- Generates detailed comparison reports

## Architecture

- **AWS AgentCore Runtime**: Orchestrates agent execution and tool coordination
- **OWASP AIBOM Generator**: Generates standardized AIBOMs for ML models
- **Hugging Face Integration**: Fetches model metadata and artifacts
- **Comparison Engine**: Analyzes differences in model components and risks

## Key Features

- ğŸ¤– **AgentCore Runtime**: Intelligent workflow orchestration with multi-step reasoning
- ğŸ”§ **Automated AIBOM Generation**: Uses OWASP standard for ML model bills of materials
- ğŸ” **AI-Powered Analysis**: Bedrock Agent provides intelligent security insights
- ğŸ“Š **Comprehensive Reporting**: Interactive HTML reports with visualizations
- â˜ï¸ **Cloud-Native**: Fully deployable to AWS with serverless execution
- ğŸ”’ **Security-First**: Identifies vulnerabilities, unsafe formats, and compliance gaps

## Quick Start

```bash
# Create virtual environment
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt

# Configure AWS credentials
aws configure

# Deploy infrastructure
python deploy.py

# Run the agent
python main.py
```

## Project Structure

```
â”œâ”€â”€ aibom_agent/
â”‚   â”œâ”€â”€ core/               # Core orchestration logic
â”‚   â”‚   â””â”€â”€ agent_orchestrator.py
â”‚   â”œâ”€â”€ services/           # Service implementations
â”‚   â”‚   â”œâ”€â”€ huggingface_service.py
â”‚   â”‚   â”œâ”€â”€ aibom_generator.py
â”‚   â”‚   â”œâ”€â”€ bedrock_agent.py
â”‚   â”‚   â”œâ”€â”€ comparison_engine.py
â”‚   â”‚   â””â”€â”€ report_generator.py
â”‚   â”œâ”€â”€ models/             # Data models
â”‚   â”‚   â””â”€â”€ analysis_result.py
â”‚   â”œâ”€â”€ config/             # Configuration
â”‚   â”‚   â””â”€â”€ settings.py
â”‚   â””â”€â”€ templates/          # HTML report templates
â”œâ”€â”€ main.py                 # AgentCore runtime entrypoint
â”œâ”€â”€ cli.py                  # Local development CLI
â”œâ”€â”€ deploy.py               # Deployment script
â”œâ”€â”€ requirements.txt        # Python dependencies
â””â”€â”€ reports/                # Generated reports output
```

## AgentCore Integration

This system uses **AWS AgentCore Runtime** for production deployment:

- **`main.py`**: AgentCore entrypoint with `@app.entrypoint` decorator
- **Intelligent Orchestration**: Multi-step reasoning for AIBOM analysis
- **Session Management**: Automatic session handling and state persistence
- **Streaming Support**: Real-time analysis progress updates
- **Production Ready**: Managed runtime with auto-scaling and monitoring

## Usage

### Local Development

```bash
# Test locally with CLI
python cli.py analyze -m microsoft/DialoGPT-medium

# Compare multiple models
python cli.py analyze -m microsoft/DialoGPT-medium -m facebook/blenderbot-400M-distill

# Run development server
python cli.py serve --port 8000

# Test with sample payloads
python cli.py test-payload
```

### AgentCore Runtime (Production)

```bash
# Configure and deploy
python deploy.py

# Or manually:
agentcore configure
agentcore deploy

# Test the deployed agent
agentcore invoke --payload '{"action": "analyze_model", "model_name": "microsoft/DialoGPT-medium"}'

# Monitor
agentcore status
agentcore logs
```